I trained a model to convert apples to oranges and vice versa.Since I trained for approximately 120 iterations (1,2 epochs) the result is pretty good in my opinion. You can see that the output image is pixelated, and the background color changed its pixel value from 255 to 0. Simply, it converted the red found in the image to orange color. All of the other values in the image, such as green leaves or the sky, receive a value of 0 or 255. I'm curious on how the model determines whether to convert a value to 0 or 255.

You can see that once the target of orange is detected, the color is changed to red and everything else gets a value of 0 or 255. The value assignment seems to be dependent on edge detection as well. Moreover, I am impressed on how the model managed to remove the watermark.
